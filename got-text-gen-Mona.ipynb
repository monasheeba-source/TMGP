{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:08.815783Z",
     "iopub.status.busy": "2022-10-06T07:26:08.815177Z",
     "iopub.status.idle": "2022-10-06T07:26:19.140398Z",
     "shell.execute_reply": "2022-10-06T07:26:19.139445Z",
     "shell.execute_reply.started": "2022-10-06T07:26:08.815739Z"
    }
   },
   "source": [
    "# üêâ Project 2: Game Of Thrones (Text Generation)\n",
    "\n",
    "üßæ**Description:** This is a classic Text Generation problem, using scriptures of famous books, Game of Thrones in this case. Open-ended language models are trending research in this era which gives rise to deep learning models with distinct architecture. In this problem, we have provided the first couple of chapters from the Classic Game Of Thrones Book. Generating text on this corpus would lead to an advancement in AI fictional corpus generation.\n",
    "\n",
    "üß≠ **Problem Statement:** You are provided with **got1**: you have to perform a step-by-step NLP approach to generate text based on input from any part of the book. Reference to performing the task has been attached below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:19.143762Z",
     "iopub.status.busy": "2022-10-06T07:26:19.143518Z",
     "iopub.status.idle": "2022-10-06T07:26:23.905487Z",
     "shell.execute_reply": "2022-10-06T07:26:23.904740Z",
     "shell.execute_reply.started": "2022-10-06T07:26:19.143730Z"
    }
   },
   "outputs": [],
   "source": [
    "# keras module for building LSTM \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:23.907147Z",
     "iopub.status.busy": "2022-10-06T07:26:23.906891Z",
     "iopub.status.idle": "2022-10-06T07:26:23.912454Z",
     "shell.execute_reply": "2022-10-06T07:26:23.911489Z",
     "shell.execute_reply.started": "2022-10-06T07:26:23.907108Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:23.915447Z",
     "iopub.status.busy": "2022-10-06T07:26:23.915153Z",
     "iopub.status.idle": "2022-10-06T07:26:23.930308Z",
     "shell.execute_reply": "2022-10-06T07:26:23.929475Z",
     "shell.execute_reply.started": "2022-10-06T07:26:23.915406Z"
    }
   },
   "outputs": [],
   "source": [
    "# set seeds for reproducability\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "# keras module for building LSTM \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:23.932988Z",
     "iopub.status.busy": "2022-10-06T07:26:23.932378Z",
     "iopub.status.idle": "2022-10-06T07:26:25.338768Z",
     "shell.execute_reply": "2022-10-06T07:26:25.337805Z",
     "shell.execute_reply.started": "2022-10-06T07:26:23.932939Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:25.340568Z",
     "iopub.status.busy": "2022-10-06T07:26:25.340296Z",
     "iopub.status.idle": "2022-10-06T07:26:25.345218Z",
     "shell.execute_reply": "2022-10-06T07:26:25.343997Z",
     "shell.execute_reply.started": "2022-10-06T07:26:25.340531Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Let‚Äôs demonstrate this with a small pipeline of text preparation including:\n",
    "\n",
    "### 1)Load the raw text.\n",
    "#### 2)Split into tokens.\n",
    "#### 3)Convert to lowercase.\n",
    "#### 4)Remove punctuation from each token.\n",
    "#### 5)Filter out remaining tokens that are not alphabetic.\n",
    "#### 6)Filter out tokens that are stop words.\n",
    "#### 7)Stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Different Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:25.347041Z",
     "iopub.status.busy": "2022-10-06T07:26:25.346405Z",
     "iopub.status.idle": "2022-10-06T07:26:25.356442Z",
     "shell.execute_reply": "2022-10-06T07:26:25.355746Z",
     "shell.execute_reply.started": "2022-10-06T07:26:25.347000Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:25.358294Z",
     "iopub.status.busy": "2022-10-06T07:26:25.357682Z",
     "iopub.status.idle": "2022-10-06T07:26:25.390314Z",
     "shell.execute_reply": "2022-10-06T07:26:25.389399Z",
     "shell.execute_reply.started": "2022-10-06T07:26:25.358255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a game of thrones \n",
      "book one of a song of ice and fire \n",
      "by george r. r. martin \n",
      "prologue \n",
      "\"we should start back,\" gared urged as the woods began to grow dark around them. \"the wildlings are \n",
      "dead.\" \n",
      "\"do the dead frighten you?\" ser waymar royce asked with just the hint of a smile. \n",
      "gared did not rise to the bait. he was an old man, past fifty, and he had seen the lordlings come and go. \n",
      "\"dead is dead,\" he said. \"we have no business with the dead.\" \n",
      "\"are they dead?\" royce asked softly. \"what proof have we?\" \n",
      "\"will saw them,\" gared said. \"if he says they are dead, that's proof enough for me.\" \n",
      "will had known they would drag him into the quarrel sooner or later. he wished it had been later rather \n",
      "than sooner. \"my mother told me that dead men sing no songs,\" he put in. \n",
      "\"my wet nurse said the same thing, will,\" royce replied. \"never believe anything you hear at a woman's \n",
      "tit. there are things to be learned even from the dead.\" his voice echoed, too loud in the twilit forest. \n",
      "page 1\n",
      "\n",
      "\"we h\n"
     ]
    }
   ],
   "source": [
    "#LOAD TEXT\n",
    "#Save notepad as UTF-8 (select from dropdown during saving)\n",
    "filename = \"got1.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "print(raw_text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:25.391943Z",
     "iopub.status.busy": "2022-10-06T07:26:25.391599Z",
     "iopub.status.idle": "2022-10-06T07:26:25.400450Z",
     "shell.execute_reply": "2022-10-06T07:26:25.399612Z",
     "shell.execute_reply.started": "2022-10-06T07:26:25.391908Z"
    }
   },
   "outputs": [],
   "source": [
    "# data cleaning process\n",
    "import re                                # Regular expressions to use sub function for replacing the useless text from the data\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r',', '', text)\n",
    "    text = re.sub(r'\\'', '',  text)\n",
    "    text = re.sub(r'\\\"', '', text)\n",
    "    text = re.sub(r'\\(', '', text)\n",
    "    text = re.sub(r'\\)', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'‚Äú', '', text)\n",
    "    text = re.sub(r'‚Äù', '', text)\n",
    "    text = re.sub(r'‚Äô', '', text)\n",
    "    text = re.sub(r'\\.', '', text)\n",
    "    text = re.sub(r';', '', text)\n",
    "    text = re.sub(r':', '', text)\n",
    "    text = re.sub(r'\\-', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:25.404325Z",
     "iopub.status.busy": "2022-10-06T07:26:25.404103Z",
     "iopub.status.idle": "2022-10-06T07:26:25.420681Z",
     "shell.execute_reply": "2022-10-06T07:26:25.419943Z",
     "shell.execute_reply.started": "2022-10-06T07:26:25.404294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a game of thrones ', 'book one of a song of ice and fire ', 'by george r. r. martin ', 'prologue ', '\"we should start back,\" gared urged as the woods began to grow dark around them. \"the wildlings are ', 'dead.\" ', '\"do the dead frighten you?\" ser waymar royce asked with just the hint of a smile. ', 'gared did not rise to the bait. he was an old man, past fifty, and he had seen the lordlings come and go. ', '\"dead is dead,\" he said. \"we have no business with the dead.\" ', '\"are they dead?\" royce asked softly. \"what proof have we?\" ', '\"will saw them,\" gared said. \"if he says they are dead, that\\'s proof enough for me.\" ', 'will had known they would drag him into the quarrel sooner or later. he wished it had been later rather ', 'than sooner. \"my mother told me that dead men sing no songs,\" he put in. ', '\"my wet nurse said the same thing, will,\" royce replied. \"never believe anything you hear at a woman\\'s ', 'tit. there are things to be learned even from the dead.\" his voice echoed, too loud in the twilit forest. ', 'page 1', '', '\"we have a long ride before us,\" gared pointed out. \"eight days, maybe nine. and night is falling.\" ', 'ser waymar royce glanced at the sky with disinterest. \"it does that every day about this time. are you ', 'unmanned by the dark, gared?\" ', \"will could see the tightness around gared's mouth, the barely sup \", 'pressed anger in his eyes under the thick black hood of his cloak. gared had spent forty years in the ', \"night's watch, man and boy, and he was not accustomed to being made light of. yet it was more than \", 'that. under the wounded pride, will could sense something else in the older man. you could taste it; a ', 'nervous tension that came perilous close to fear. ', 'will shared his unease. he had been four years on the wall. the first time he had been sent beyond, all ', 'the old stories had come rushing back, and his bowels had turned to water. he had laughed about it ', 'afterward. he was a veteran of a hundred rangings by now, and the endless dark wilderness that the ', 'southron called the haunted forest had no more terrors for him. ', 'until tonight. something was different tonight. there was an edge to this darkness that made his hackles ', 'rise. nine days they had been riding, north and northwest and then north again, farther and farther from ', 'the wall, hard on the track of a band of wildling raiders. each day had been worse than the day that had ', 'come before it. today was the worst of all. a cold wind was blowing out of the north, and it made the ', 'trees rustle like living things. all day, will had felt as though something were watching him, something ', 'cold and implacable that loved him not. gared had felt it too. will wanted nothing so much as to ride ', 'hellbent for the safety of the wall, but that was not a feeling to share with your commander. ', 'especially not a commander like this one. ', 'ser waymar royce was the youngest son of an ancient house with too many heirs. he was a handsome ', 'youth of eighteen, grey-eyed and graceful and slender as a knife. mounted on his huge black destrier, the ', 'knight towered above will and gared on their smaller garrons. he wore black leather boots, black ', 'woolen pants, black moleskin gloves, and a fine supple coat of gleaming black ringmail over layers of ', \"black wool and boiled leather. ser waymar had been a sworn brother of the night's watch for less than \", 'half a year, but no one could say he had not prepared for his vocation. at least insofar as his wardrobe ', 'was concerned. ', 'his cloak was his crowning glory; sable, thick and black and soft as sin. \"bet he killed them all himself, ', 'he did,\" gared told the barracks over wine, \"twisted their little heads off, our mighty warrior.\" they had ', 'all shared the laugh. ', 'it is hard to take orders from a man you laughed at in your cups, will reflected as he sat shivering atop ', 'his garron. gared must have felt the same. ', '\"mormont said as we should track them, and we did,\" gared said. ', '\"they\\'re dead. they shan\\'t trouble us no more. there\\'s hard riding before us. i don\\'t like this weather. if ', \"it snows, we could be a fortnight getting back, and snow's the best we can hope for. ever seen an ice \", 'storm, my lord?\" ', 'the lordling seemed not to hear him. he studied the deepening twilight in that half-bored, half-distracted ', 'page 2', '', 'way he had. will had ridden with the knight long enough to understand that it was best not to interrupt ', 'him when he looked like that. \"tell me again what you saw, will. all the details. leave nothing out.\" ', \"will had been a hunter before he joined the night's watch. well, a poacher in truth. mallister freeriders \", \"had caught him red-handed in the mallisters' own woods, skinning one of the mallisters' own bucks, and \", 'it had been a choice of putting on the black or losing a hand. no one could move through the woods as ', 'silent as will, and it had not taken the black brothers long to discover his talent. ', '\"the camp is two miles farther on, over that ridge, hard beside a stream,\" will said. \"i got close as i ', \"dared. there's eight of them, men and women both. no children i could see. they put up a lean-to \", \"against the rock. the snow's pretty well covered it now, but i could still make it out. no fire burning, but \", 'the firepit was still plain as day. no one moving. i watched a long time. no living man ever lay so still.\" ', '\"did you see any blood?\" ', '\"well, no,\" will admitted. ', '\"did you see any weapons?\" ', '\"some swords, a few bows. one man had an axe. heavy-looking, double-bladed, a cruel piece of iron. ', 'it was on the ground beside him, right by his hand.\" ', '\"did you make note of the position of the bodies?\" ', 'will shrugged. \"a couple are sitting up against the rock. most of them on the ground. fallen, like.\" ', '\"or sleeping,\" royce suggested. ', '\"fallen,\" will insisted. \"there\\'s one woman up an ironwood, halfhid in the branches. a far-eyes.\" he ', 'smiled thinly. \"i took care she never saw me. when i got closer, i saw that she wasn\\'t moving neither.\" ', 'despite himself, he shivered. ', '\"you have a chill?\" royce asked. ', '\"some,\" will muttered. \"the wind, m\\'lord.\" ', 'the young knight turned back to his grizzled man-at-arms. frostfallen leaves whispered past them, and ', 'royce\\'s destrier moved restlessly. \"what do you think might have killed these men, gared?\" ser ', 'waymar asked casually. he adjusted the drape of his long sable cloak. ', '\"it was the cold,\" gared said with iron certainty. \"i saw men freeze ', 'last winter, and the one before, when i was half a boy. everyone talks about snows forty foot deep, and ', 'how the ice wind comes howling out of the north, but the real enemy is the cold. it steals up on you ', 'quieter than will, and at first you shiver and your teeth chatter and you stamp your feet and dream of ', 'mulled wine and nice hot fires. it burns, it does. nothing burns like the cold. but only for a while. then it ', \"gets inside you and starts to fill you up, and after a while you don't have the strength to fight it. it's easier \", \"just to sit down or go to sleep. they say you don't feel any pain toward the end. first you go weak and \", 'drowsy, and everything starts to fade, and then it\\'s like sinking into a sea of warm milk. peaceful, like.\" ', '\"such eloquence, gared,\" ser waymar observed. \"i never suspected you had it in you.\" ', 'page 3', '', '\"i\\'ve had the cold in me too, lordling.\" gared pulled back his hood, giving ser waymar a good long look ', 'at the stumps where his ears had been. \"two ears, three toes, and the little finger off my left hand. i got ', 'off light. we found my brother frozen at his watch, with a smile on his face.\" ', 'ser waymar shrugged. \"you ought dress more warmly, gared.\" ', 'gared glared at the lordling, the scars around his ear holes flushed red with anger where maester ', 'aemon had cut the ears away. \"we\\'ll see how warm you can dress when the winter comes.\" he pulled ', 'up his hood and hunched over his garron, silent and sullen. ']\n"
     ]
    }
   ],
   "source": [
    "# cleaning the data\n",
    "lower_data = raw_text.lower()           # Converting the string to lower case to get uniformity\n",
    "\n",
    "split_data = lower_data.splitlines()      # Splitting the data to get every line seperately but this will give the list of uncleaned data\n",
    "\n",
    "print(split_data[0:100])                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:25.422316Z",
     "iopub.status.busy": "2022-10-06T07:26:25.421999Z",
     "iopub.status.idle": "2022-10-06T07:26:25.843576Z",
     "shell.execute_reply": "2022-10-06T07:26:25.842659Z",
     "shell.execute_reply.started": "2022-10-06T07:26:25.422280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a game of thrones \n",
      "book one of a song of ice and fire \n",
      "by george r r martin \n",
      "prologue \n",
      "we should st\n"
     ]
    }
   ],
   "source": [
    "final = ''                                # initiating a argument with blank string to hold the values of final cleaned data\n",
    "\n",
    "for line in split_data:\n",
    "    line = clean_text(line)\n",
    "    final += '\\n' + line\n",
    "\n",
    "print(final[0:100])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:25.850874Z",
     "iopub.status.busy": "2022-10-06T07:26:25.847524Z",
     "iopub.status.idle": "2022-10-06T07:26:25.864113Z",
     "shell.execute_reply": "2022-10-06T07:26:25.863409Z",
     "shell.execute_reply.started": "2022-10-06T07:26:25.850828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'a game of thrones ', 'book one of a song of ice and fire ', 'by george r r martin ', 'prologue ', 'we should start back gared urged as the woods began to grow dark around them the wildlings are ', 'dead ', 'do the dead frighten you? ser waymar royce asked with just the hint of a smile ', 'gared did not rise to the bait he was an old man past fifty and he had seen the lordlings come and go ', 'dead is dead he said we have no business with the dead ', 'are they dead? royce asked softly what proof have we? ', 'will saw them gared said if he says they are dead thats proof enough for me ', 'will had known they would drag him into the quarrel sooner or later he wished it had been later rather ', 'than sooner my mother told me that dead men sing no songs he put in ', 'my wet nurse said the same thing will royce replied never believe anything you hear at a womans ', 'tit there are things to be learned even from the dead his voice echoed too loud in the twilit forest ', 'page 1', '', 'we have a long ride before us gared pointed out eight days maybe nine and night is falling ', 'ser waymar royce glanced at the sky with disinterest it does that every day about this time are you ', 'unmanned by the dark gared? ', 'will could see the tightness around gareds mouth the barely sup ', 'pressed anger in his eyes under the thick black hood of his cloak gared had spent forty years in the ', 'nights watch man and boy and he was not accustomed to being made light of yet it was more than ', 'that under the wounded pride will could sense something else in the older man you could taste it a ', 'nervous tension that came perilous close to fear ', 'will shared his unease he had been four years on the wall the first time he had been sent beyond all ', 'the old stories had come rushing back and his bowels had turned to water he had laughed about it ', 'afterward he was a veteran of a hundred rangings by now and the endless dark wilderness that the ', 'southron called the haunted forest had no more terrors for him ', 'until tonight something was different tonight there was an edge to this darkness that made his hackles ', 'rise nine days they had been riding north and northwest and then north again farther and farther from ', 'the wall hard on the track of a band of wildling raiders each day had been worse than the day that had ', 'come before it today was the worst of all a cold wind was blowing out of the north and it made the ', 'trees rustle like living things all day will had felt as though something were watching him something ', 'cold and implacable that loved him not gared had felt it too will wanted nothing so much as to ride ', 'hellbent for the safety of the wall but that was not a feeling to share with your commander ', 'especially not a commander like this one ', 'ser waymar royce was the youngest son of an ancient house with too many heirs he was a handsome ', 'youth of eighteen greyeyed and graceful and slender as a knife mounted on his huge black destrier the ', 'knight towered above will and gared on their smaller garrons he wore black leather boots black ', 'woolen pants black moleskin gloves and a fine supple coat of gleaming black ringmail over layers of ', 'black wool and boiled leather ser waymar had been a sworn brother of the nights watch for less than ', 'half a year but no one could say he had not prepared for his vocation at least insofar as his wardrobe ', 'was concerned ', 'his cloak was his crowning glory sable thick and black and soft as sin bet he killed them all himself ', 'he did gared told the barracks over wine twisted their little heads off our mighty warrior they had ', 'all shared the laugh ', 'it is hard to take orders from a man you laughed at in your cups will reflected as he sat shivering atop ', 'his garron gared must have felt the same ', 'mormont said as we should track them and we did gared said ', 'theyre dead they shant trouble us no more theres hard riding before us i dont like this weather if ', 'it snows we could be a fortnight getting back and snows the best we can hope for ever seen an ice ', 'storm my lord? ', 'the lordling seemed not to hear him he studied the deepening twilight in that halfbored halfdistracted ', 'page 2', '', 'way he had will had ridden with the knight long enough to understand that it was best not to interrupt ', 'him when he looked like that tell me again what you saw will all the details leave nothing out ', 'will had been a hunter before he joined the nights watch well a poacher in truth mallister freeriders ', 'had caught him redhanded in the mallisters own woods skinning one of the mallisters own bucks and ', 'it had been a choice of putting on the black or losing a hand no one could move through the woods as ', 'silent as will and it had not taken the black brothers long to discover his talent ', 'the camp is two miles farther on over that ridge hard beside a stream will said i got close as i ', 'dared theres eight of them men and women both no children i could see they put up a leanto ', 'against the rock the snows pretty well covered it now but i could still make it out no fire burning but ', 'the firepit was still plain as day no one moving i watched a long time no living man ever lay so still ', 'did you see any blood? ', 'well no will admitted ', 'did you see any weapons? ', 'some swords a few bows one man had an axe heavylooking doublebladed a cruel piece of iron ', 'it was on the ground beside him right by his hand ', 'did you make note of the position of the bodies? ', 'will shrugged a couple are sitting up against the rock most of them on the ground fallen like ', 'or sleeping royce suggested ', 'fallen will insisted theres one woman up an ironwood halfhid in the branches a fareyes he ', 'smiled thinly i took care she never saw me when i got closer i saw that she wasnt moving neither ', 'despite himself he shivered ', 'you have a chill? royce asked ', 'some will muttered the wind mlord ', 'the young knight turned back to his grizzled manatarms frostfallen leaves whispered past them and ', 'royces destrier moved restlessly what do you think might have killed these men gared? ser ', 'waymar asked casually he adjusted the drape of his long sable cloak ', 'it was the cold gared said with iron certainty i saw men freeze ', 'last winter and the one before when i was half a boy everyone talks about snows forty foot deep and ', 'how the ice wind comes howling out of the north but the real enemy is the cold it steals up on you ', 'quieter than will and at first you shiver and your teeth chatter and you stamp your feet and dream of ', 'mulled wine and nice hot fires it burns it does nothing burns like the cold but only for a while then it ', 'gets inside you and starts to fill you up and after a while you dont have the strength to fight it its easier ', 'just to sit down or go to sleep they say you dont feel any pain toward the end first you go weak and ', 'drowsy and everything starts to fade and then its like sinking into a sea of warm milk peaceful like ', 'such eloquence gared ser waymar observed i never suspected you had it in you ', 'page 3', '', 'ive had the cold in me too lordling gared pulled back his hood giving ser waymar a good long look ', 'at the stumps where his ears had been two ears three toes and the little finger off my left hand i got ', 'off light we found my brother frozen at his watch with a smile on his face ', 'ser waymar shrugged you ought dress more warmly gared ', 'gared glared at the lordling the scars around his ear holes flushed red with anger where maester ', 'aemon had cut the ears away well see how warm you can dress when the winter comes he pulled ']\n"
     ]
    }
   ],
   "source": [
    "final_data = final.split('\\n')       # splitting again to get list of cleaned and splitted data ready to be processed\n",
    "print(final_data[0:100]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:25.870520Z",
     "iopub.status.busy": "2022-10-06T07:26:25.868531Z",
     "iopub.status.idle": "2022-10-06T07:26:26.511350Z",
     "shell.execute_reply": "2022-10-06T07:26:26.510539Z",
     "shell.execute_reply.started": "2022-10-06T07:26:25.870481Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Instantiating the Tokenizer\n",
    "max_vocab = 50\n",
    "tokenizer = Tokenizer(num_words=max_vocab)\n",
    "tokenizer.fit_on_texts(final_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:26.518156Z",
     "iopub.status.busy": "2022-10-06T07:26:26.516144Z",
     "iopub.status.idle": "2022-10-06T07:26:26.527535Z",
     "shell.execute_reply": "2022-10-06T07:26:26.526581Z",
     "shell.execute_reply.started": "2022-10-06T07:26:26.518114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12512\n"
     ]
    }
   ],
   "source": [
    "# Getting the total number of words of the data.\n",
    "word2idx = tokenizer.word_index\n",
    "print(len(word2idx))\n",
    "###print(word2idx)\n",
    "vocab_size = len(word2idx) + 1        # Adding 1 to the vocab_size because the index starts from 1 not 0. This will make it uniform when using it further\n",
    "###print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:26.534363Z",
     "iopub.status.busy": "2022-10-06T07:26:26.532139Z",
     "iopub.status.idle": "2022-10-06T07:26:27.264293Z",
     "shell.execute_reply": "2022-10-06T07:26:27.263454Z",
     "shell.execute_reply.started": "2022-10-06T07:26:26.534318Z"
    }
   },
   "outputs": [],
   "source": [
    "# We will turn the sentences to sequences line by line and create n_gram sequences\n",
    "\n",
    "input_seq = []\n",
    "\n",
    "for line in final_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_seq = token_list[:i+1]\n",
    "        input_seq.append(n_gram_seq)\n",
    "\n",
    "####print(input_seq)\n",
    "####print(input_seq[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:27.270607Z",
     "iopub.status.busy": "2022-10-06T07:26:27.268682Z",
     "iopub.status.idle": "2022-10-06T07:26:27.299915Z",
     "shell.execute_reply": "2022-10-06T07:26:27.299303Z",
     "shell.execute_reply.started": "2022-10-06T07:26:27.270564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# Getting the maximum length of sequence for padding purpose\n",
    "max_seq_length = max(len(x) for x in input_seq)\n",
    "print(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:27.305390Z",
     "iopub.status.busy": "2022-10-06T07:26:27.303533Z",
     "iopub.status.idle": "2022-10-06T07:26:27.579264Z",
     "shell.execute_reply": "2022-10-06T07:26:27.578420Z",
     "shell.execute_reply.started": "2022-10-06T07:26:27.305353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  4  5]\n",
      " [ 0  0  0 ...  0 46  5]\n",
      " [ 0  0  0 ... 46  5  4]\n",
      " ...\n",
      " [ 0  0  0 ... 11  5  1]\n",
      " [ 0  0  0 ...  5  1 18]\n",
      " [ 0  0  0 ...  1 18  1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Padding the sequences and converting them to array\n",
    "input_seq = np.array(pad_sequences(input_seq, maxlen=max_seq_length, padding='pre'))\n",
    "print(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:27.581190Z",
     "iopub.status.busy": "2022-10-06T07:26:27.580743Z",
     "iopub.status.idle": "2022-10-06T07:26:27.588771Z",
     "shell.execute_reply": "2022-10-06T07:26:27.588004Z",
     "shell.execute_reply.started": "2022-10-06T07:26:27.581150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs:  [[ 0  0  0 ...  0  0  4]\n",
      " [ 0  0  0 ...  0  0 46]\n",
      " [ 0  0  0 ...  0 46  5]\n",
      " ...\n",
      " [ 0  0  0 ...  1 11  5]\n",
      " [ 0  0  0 ... 11  5  1]\n",
      " [ 0  0  0 ...  5  1 18]]\n",
      "labels: [ 5  5  4 ...  1 18  1]\n"
     ]
    }
   ],
   "source": [
    "# Taking xs and labels to train the model.\n",
    "\n",
    "xs = input_seq[:, :-1]        # xs contains every word in sentence except the last one because we are using this value to predict the y value\n",
    "labels = input_seq[:, -1]     # labels contains only the last word of the sentence which will help in hot encoding the y value in next step\n",
    "print(\"xs: \",xs)\n",
    "print(\"labels:\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:27.590500Z",
     "iopub.status.busy": "2022-10-06T07:26:27.590067Z",
     "iopub.status.idle": "2022-10-06T07:26:27.864518Z",
     "shell.execute_reply": "2022-10-06T07:26:27.863718Z",
     "shell.execute_reply.started": "2022-10-06T07:26:27.590464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# one-hot encoding the labels according to the vocab size\n",
    "\n",
    "# The matrix is square matrix of the size of vocab_size. Each row will denote a label and it will have \n",
    "# a single +ve value(i.e 1) for that label and other values will be zero. \n",
    "\n",
    "ys = to_categorical(labels, num_classes=vocab_size)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:27.866896Z",
     "iopub.status.busy": "2022-10-06T07:26:27.865976Z",
     "iopub.status.idle": "2022-10-06T07:26:27.873587Z",
     "shell.execute_reply": "2022-10-06T07:26:27.872604Z",
     "shell.execute_reply.started": "2022-10-06T07:26:27.866850Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:27.875651Z",
     "iopub.status.busy": "2022-10-06T07:26:27.875339Z",
     "iopub.status.idle": "2022-10-06T07:26:31.641862Z",
     "shell.execute_reply": "2022-10-06T07:26:31.641030Z",
     "shell.execute_reply.started": "2022-10-06T07:26:27.875605Z"
    }
   },
   "outputs": [],
   "source": [
    "# using the pipeline method of sequential to define a model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,64 , input_length=max_seq_length-1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(20, return_sequences=True))\n",
    "model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(vocab_size, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:31.643453Z",
     "iopub.status.busy": "2022-10-06T07:26:31.643184Z",
     "iopub.status.idle": "2022-10-06T07:26:31.656719Z",
     "shell.execute_reply": "2022-10-06T07:26:31.655941Z",
     "shell.execute_reply.started": "2022-10-06T07:26:31.643412Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:31.658334Z",
     "iopub.status.busy": "2022-10-06T07:26:31.658074Z",
     "iopub.status.idle": "2022-10-06T07:26:31.670423Z",
     "shell.execute_reply": "2022-10-06T07:26:31.669407Z",
     "shell.execute_reply.started": "2022-10-06T07:26:31.658297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 16, 64)            800832    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 64)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 16, 20)            6800      \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 16, 40)           6560      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 40)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12513)             513033    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12513)             156587682 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 157,914,907\n",
      "Trainable params: 157,914,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:26:31.671770Z",
     "iopub.status.busy": "2022-10-06T07:26:31.671492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3380/3380 [==============================] - 2251s 662ms/step - loss: 3.4510 - accuracy: 0.1459\n",
      "Epoch 2/30\n",
      "3380/3380 [==============================] - 4874s 1s/step - loss: 3.2894 - accuracy: 0.1640\n",
      "Epoch 3/30\n",
      "3380/3380 [==============================] - 2024s 599ms/step - loss: 3.2375 - accuracy: 0.1733\n",
      "Epoch 4/30\n",
      "3380/3380 [==============================] - 2024s 599ms/step - loss: 3.2130 - accuracy: 0.1760\n",
      "Epoch 5/30\n",
      "3380/3380 [==============================] - 2012s 595ms/step - loss: 3.1983 - accuracy: 0.1774\n",
      "Epoch 6/30\n",
      "3380/3380 [==============================] - 2416s 715ms/step - loss: 3.1852 - accuracy: 0.1797\n",
      "Epoch 7/30\n",
      "3380/3380 [==============================] - 1952s 577ms/step - loss: 3.1736 - accuracy: 0.1816\n",
      "Epoch 8/30\n",
      "3380/3380 [==============================] - 1912s 566ms/step - loss: 3.1622 - accuracy: 0.1831\n",
      "Epoch 9/30\n",
      "3380/3380 [==============================] - 1921s 568ms/step - loss: 3.1522 - accuracy: 0.1837\n",
      "Epoch 10/30\n",
      "3380/3380 [==============================] - 1926s 570ms/step - loss: 3.1410 - accuracy: 0.1858\n",
      "Epoch 11/30\n",
      "3380/3380 [==============================] - 1926s 570ms/step - loss: 3.1306 - accuracy: 0.1877\n",
      "Epoch 12/30\n",
      "3380/3380 [==============================] - 1924s 569ms/step - loss: 3.1170 - accuracy: 0.1888\n",
      "Epoch 13/30\n",
      "3380/3380 [==============================] - 1930s 571ms/step - loss: 3.1055 - accuracy: 0.1906\n",
      "Epoch 14/30\n",
      "3380/3380 [==============================] - 1923s 569ms/step - loss: 3.0896 - accuracy: 0.1926\n",
      "Epoch 15/30\n",
      "3380/3380 [==============================] - 1926s 570ms/step - loss: 3.0748 - accuracy: 0.1944\n",
      "Epoch 16/30\n",
      "3380/3380 [==============================] - 1923s 569ms/step - loss: 3.0577 - accuracy: 0.1972\n",
      "Epoch 17/30\n",
      "3380/3380 [==============================] - 1922s 569ms/step - loss: 3.0396 - accuracy: 0.1996\n",
      "Epoch 18/30\n",
      "3380/3380 [==============================] - 1925s 569ms/step - loss: 3.0199 - accuracy: 0.2025\n",
      "Epoch 19/30\n",
      "3380/3380 [==============================] - 1917s 567ms/step - loss: 2.9984 - accuracy: 0.2053\n",
      "Epoch 20/30\n",
      "3380/3380 [==============================] - 1919s 568ms/step - loss: 2.9770 - accuracy: 0.2079\n",
      "Epoch 21/30\n",
      "3380/3380 [==============================] - 2152s 637ms/step - loss: 2.9519 - accuracy: 0.2108\n",
      "Epoch 22/30\n",
      "3380/3380 [==============================] - 2249s 665ms/step - loss: 2.9261 - accuracy: 0.2168\n",
      "Epoch 23/30\n",
      "3380/3380 [==============================] - 1999s 592ms/step - loss: 2.9013 - accuracy: 0.2200\n",
      "Epoch 24/30\n",
      "3380/3380 [==============================] - 1916s 567ms/step - loss: 2.8733 - accuracy: 0.2253\n",
      "Epoch 25/30\n",
      "3380/3380 [==============================] - 1928s 571ms/step - loss: 2.8462 - accuracy: 0.2296\n",
      "Epoch 26/30\n",
      "3380/3380 [==============================] - 1925s 569ms/step - loss: 2.8181 - accuracy: 0.2345\n",
      "Epoch 27/30\n",
      "3380/3380 [==============================] - 1920s 568ms/step - loss: 2.7914 - accuracy: 0.2417\n",
      "Epoch 28/30\n",
      "3380/3380 [==============================] - 1910s 565ms/step - loss: 2.7603 - accuracy: 0.2476\n",
      "Epoch 29/30\n",
      "3380/3380 [==============================] - 1910s 565ms/step - loss: 2.7351 - accuracy: 0.2507\n",
      "Epoch 30/30\n",
      "3380/3380 [==============================] - 1892s 560ms/step - loss: 2.7056 - accuracy: 0.2579\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(xs,ys,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x195871b5be0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiwklEQVR4nO3deXSV9b3v8feXEEYhzCQEwjyPYgRFq4KigFa07ak4XW1VtFatPXZQ2+NpT9c59Z5je+pd16GIWOtEW6SWXkHhWBUtgiSChFlIgATIDCEQMu7v/SNbV4oBNiHwZO/9ea3FIs+Y72895JOH3/Pbv8fcHRERiX2tgi5ARETODgW+iEicUOCLiMQJBb6ISJxQ4IuIxInWQRfQmB49eviAAQOCLkNEJGpkZmYWu3vPE+3TIgN/wIABZGRkBF2GiEjUMLPdJ9tHXToiInEiosA3sxlmts3MdpjZw41sv9nMNoT/rDKz8Q22dTGzRWa21cy2mNmFzdkAERGJzEm7dMwsAXgKmA7kAWvNbIm7b26wWw5wqbsfMLOZwDxgcnjbk8Bb7v4NM2sDdGjWFoiISEQiucOfBOxw92x3rwYWArMb7uDuq9z9QHhxNdAXwMw6A5cAz4f3q3b3g81Uu4iInIJIAj8VyG2wnBdedzx3AMvCXw8CioAXzGydmc03s45NqlRERE5LJIFvjaxrdMY1M5tKfeD/OLyqNTAReMbdzwWOAF96BhA+dq6ZZZhZRlFRUQRliYjIqYgk8POAfg2W+wL7jt3JzMYB84HZ7l7S4Ng8d18TXl5E/S+AL3H3ee6e7u7pPXuecCipiIg0QSSBvxYYamYDww9d5wBLGu5gZmnAYuBWd9/++Xp3zwdyzWx4eNXlQMOHvSIiAmTsKmX+B9mcySnrTzpKx91rzew+4G0gAVjg7pvM7J7w9meBx4DuwNNmBlDr7unhU9wPvBL+ZZENfKv5myEiEr1ySyu4+6VMOrdP5MZJaXRse2Y+E2st8QUo6enprk/aikg8OFxVyzeeWcXeg0d547sXMbjnOU06j5llNrjRblSLnFpBRCQehELOgwvX81nhYV64/fwmh32kNLWCiEhA/vPtbfzPlgL+5eqRXDLszA9WUeCLiATg9cw8nn1/JzdNTuO2KQPOyvdU4IuInGWZuw/wyOIsLhzUnZ9fO5rwYJczToEvInIW7T14lLtfyiClSzuevnkiiQlnL4b10FZE5Cw5UlXLnS9mUFUTYuHcdLp2bHNWv78CX0TkLAiFnO//YT3b8g+x4PbzGdKr01mvQV06IiJnwa9WbGP55gJ+cvUoLhveK5AaFPgiImfYX9bv5al3dzLn/H58+6IBgdWhwBcROYPW7TnADxdtYPLAbvzb7DFnbUROY9SHLyJyBtTWhfjzur08vmwryZ3b8cwt59GmdbD32Ap8EZFmFAo5b23K51fLt7Gz6AhjU5P47xsm0O0sj8hpjAJfRKQZuDvvby/iieXb2Lj3EEN6ncOzt0zkqtHJgXbjNKTAFxE5TWt3lfJfb23j412l9O3anl/903iuOzeVhFYtI+g/p8AXEWmijXvLeGL5Nt7bVkTPTm35xezR3HB+WuB99cejwBcROUV5Byr45dKtvJm1n6T2ifx4xghunzKA9m0Sgi7thBT4IiKnYFfxEebMW82hyhrunzaEO78yiKT2iUGXFREFvohIhD4P++q6EK9/ZwojUzoHXdIpaZkdTSIiLcyu4iPc+NxqqmrreOXOyVEX9qDAFxE5qd0l9WFfWVPHq3ddEJVhDwp8EZET2l1S340T7WEPCnwRkeNqGPav3BndYQ8KfBGRRu0pqeDGBmE/qk90hz1olI6IyJfsKalgzryPqKip49UYCXvQHb6IyD9oGPav3Dk5ZsIeFPgiIl/YU1LBjc+t/iLsR/dJCrqkZqXAFxEBCg9VcuNzqzlSXcvLd8Re2EOEgW9mM8xsm5ntMLOHG9l+s5ltCP9ZZWbjj9meYGbrzOz/NVfhIiLNpbKmjrkvZVJ6pJqX75jMmNTYC3uIIPDNLAF4CpgJjAJuNLNRx+yWA1zq7uOAXwDzjtn+PWDL6ZcrItK83J1HF2exPvcg/33DhJgNe4jsDn8SsMPds929GlgIzG64g7uvcvcD4cXVQN/Pt5lZX+BqYH7zlCwi0nx+uzKbxev28tD0YcwYkxx0OWdUJIGfCuQ2WM4LrzueO4BlDZZ/A/wICJ3om5jZXDPLMLOMoqKiCMoSETk972wp4H+/tZVrxqVw37QhQZdzxkUS+I29ssUb3dFsKvWB/+Pw8jVAobtnnuybuPs8d0939/SePXtGUJaISNNtLyjnewvXM6ZPEv/1jfEt5jWEZ1IkH7zKA/o1WO4L7Dt2JzMbR323zUx3Lwmvvgi41sxmAe2Azmb2srvfcnpli4g03YEj1dz5Ygbt2yQw73+d1+JfXNJcIrnDXwsMNbOBZtYGmAMsabiDmaUBi4Fb3X375+vd/RF37+vuA8LH/U1hLyJBqqkLce8rn5B/qJLf3noeKUntgy7prDnpHb6715rZfcDbQAKwwN03mdk94e3PAo8B3YGnw/8tqnX39DNXtohI0/z8r5v4KLuEX39zPBPTugZdzlll7o12xwcqPT3dMzIygi5DRGLMS6t38y9vbOTuSwfxyMyRQZfTrMws82Q32vqkrYjEhVU7i/nZkk1MG9GLH101IuhyAqHAF5GYt7vkCPe+8gmDenTkyTkTSGgV+yNyGqPAF5GYVl5Zwx0v1ncRz78tnU7tEgOuKDgKfBGJWQWHKrnl+Y/JKT7C0zdNpH/3jkGXFCi9AEVEYtK6PQe4+6VMDlfV8vTNE5kypEfQJQVOgS8iMWdRZh6PLs6id1Jbfn/HFEYkx85LTE6HAl9EYkZtXYhfLtvK8x/mMGVwd566aSJdO7YJuqwWQ4EvIjHhYEU197+2jg8+K+b2KQP46dUjaZ2gx5QNKfBFJOptLyjnrt9nsO/gUf7z6+P45vn9Tn5QHFLgi0hUW7G5gAcXrqN9m9YsnHsB5/XvFnRJLZYCX0Sikrvz1Ls7+NWK7YxNTYq7idCaQoEvIlGnvLKGh1/P4s2s/Vx/biq//NpY2iXGxxTHp0OBLyJRZX3uQR54bR17Dx7l0VkjuOsrg+Li5SXNQYEvIlEhFHLmfZDNE29vo3fndvxh7gWkD1B//alQ4ItIi1dYXslDf/yUDz4rZuaYZB7/2jiSOsTvnDhNpcAXkRbt/e1FPPTH9ZRX1vIf14/lxkn91IXTRAp8EWmRqmtDPLF8G/NWZjO8dydevesChvXuFHRZUU2BLyItzq7iIzywcB0b8sq45YI0fnr1KI3CaQYKfBFpUd5Yt5ef/DmLhFbGs7dMZMaYlKBLihkKfBFpEepCzr8u2cjLq/dw/oCu/GbOuaR20QepmpMCX0QCd7S6jgcWrmPF5gLuvmQQP7xquCY+OwMU+CISqANHqrnjxbWsyz3Iz68dzW1TBgRdUsxS4ItIYPIOVHDbgo/JPXCUp26ayKyx6q8/kxT4IhKIzfsOcfsLH3O0po6Xvj2JyYO6B11SzFPgi8hZt2pHMXNfyqRTu9YsumcKw5M1vv5sUOCLyFm15NN9PPTH9Qzs0ZHffWsSfTQS56yJ6DG4mc0ws21mtsPMHm5k+81mtiH8Z5WZjQ+v72dm75rZFjPbZGbfa+4GiEj0mP9BNg+8to5z07ryp7unKOzPspPe4ZtZAvAUMB3IA9aa2RJ339xgtxzgUnc/YGYzgXnAZKAWeMjdPzGzTkCmma045lgRiXGhkPMfS7cw/8McZo5J5r9vmKBPzgYgki6dScAOd88GMLOFwGzgi9B291UN9l8N9A2v3w/sD39dbmZbgNSGx4pIbCsqr+JnSzbxZtZ+bruwP499dTQJrTT5WRAiCfxUILfBch71d+/Hcwew7NiVZjYAOBdY09hBZjYXmAuQlpYWQVki0pKVHa3huZXZLPh7DlW1IX48YwT3XKqXlQQpksBv7Op4ozuaTaU+8C8+Zv05wOvAg+5+qLFj3X0e9V1BpKenN3p+EWn5jlbX8eJHu3jmvZ2UHa3hmnEp/PP0YQzqeU7QpcW9SAI/D+jXYLkvsO/YncxsHDAfmOnuJQ3WJ1If9q+4++LTK1dEWqqauhB/WJvL/3nnMwrLq7hseE9+cOVwxqQmBV2ahEUS+GuBoWY2ENgLzAFuariDmaUBi4Fb3X17g/UGPA9scfdfN1vVItJihELOXzfs49crtrO7pIL0/l35vzdNZNJAvX6wpTlp4Lt7rZndB7wNJAAL3H2Tmd0T3v4s8BjQHXg63D9X6+7pwEXArUCWma0Pn/JRd1/a7C0RkbPK3XlnSyFPLN/G1vxyRqZ0ZsHt6Uwd3kv99C2Uube87vL09HTPyMgIugwROY7auhA/+NOnvLF+HwO6d+CfrxzONWNTaKXRN4Exs8zwjfZx6ZO2InJK6kL+Rdh/7/Kh3DdtCImayjgqKPBFJGJ1IeeH4bD/4VXD+e7UIUGXJKdAv5ZFJCJ1IedHizaweN1eHpo+TGEfhRT4InJSoZDz8OsbeP2TPB68Yij3Xz406JKkCRT4InJCoZDz6J+z+FNmHg9cPpQHrxgWdEnSRAp8ETmuUMj5yRtZLFyby/3ThvD9K3RnH80U+CLSqFDI+elfNvLax7l8d+pg/nn6MI2vj3IKfBH5EnfnsSUbeXXNHr5z2WB+cOVwhX0MUOCLyD9wd362ZBMvr97D3ZcO4kdXKexjhcbhi8gXKqpr+eXSrby0ejd3fWUgD88YobCPIQp8EaG8soaXVu/m+Q9yKDlSzZ0XD+TRWSMV9jFGgS8Sx8oqanhhVQ4v/H0XZUdruHRYT+6fNoT0AZrpMhYp8EXiUMnhKp7/MIfff7Sbw1W1TB/Vm/unDWFc3y5BlyZnkAJfJI4UHqpk3spsXlmzh8raOmaNTeG+qUMYmdI56NLkLFDgi8SB3NIKnvsgm4Vrc6kLObPH9+HeqYMZ0qtT0KXJWaTAF4lR7s4new7w/Ic5vLUxn1ZmfH1iX+6dOpj+3TsGXZ4EQIEvEmNq6kIs25jP8x/m8GnuQTq3a81dlwzitgsH0KdL+6DLkwAp8EViRFlFDa+t3cOLq3axv6ySgT068m+zR/P1iX3p2FY/6qLAF4l6OcVHeOHvOSzKzKOiuo4LB3XnF7PHMG1EL71yUP6BAl8kSmXuLuWZ97J5Z2sBia1a8dXxffj2xQMY3Scp6NKkhVLgi0QRd+e97UU8895OPs4ppWuHRO6fOoRbLuxPr07tgi5PWjgFvkgUqAs5b2bt55n3drJl/yFSktrx2DWjmDOpHx3a6MdYIqN/KSItWGVNHYs/2ctvV+5kd0kFg3t25L++MY7ZE1Jp01qT3cqpUeCLtEDllTW8umYP8z/Moai8ivF9k3jklvO4clRvPYiVJlPgi7QgByuqWfBhDr9btYtDlbVcPKQHT94wgQsHd9fMlXLaFPgiLUDJ4Srmf5jD71ft4kh1HVeN7s29lw1hfL8uQZcmMSSiwDezGcCTQAIw390fP2b7zcCPw4uHge+4+6eRHCsSzwrLK3luZTYvr66fzOzqsSncP20ow5M1x400v5MGvpklAE8B04E8YK2ZLXH3zQ12ywEudfcDZjYTmAdMjvBYkbiTX1bJb1fu5NU1e6ipCzF7Qirf1WRmcoZFcoc/Cdjh7tkAZrYQmA18EdruvqrB/quBvpEeKxJP9h48yrPv7eQPa3Opc+f6c1P57tQhDOyhyczkzIsk8FOB3AbLecDkE+x/B7DsVI81s7nAXIC0tLQIyhKJHhv3lvHy6t28/kkeAN84ry/fuXQIad07BFyZxJNIAr+xoQHe6I5mU6kP/ItP9Vh3n0d9VxDp6emN7iMSTcora1jy6T4WfpxL1t4y2rZuxQ3n9+OeSwfTt6uCXs6+SAI/D+jXYLkvsO/YncxsHDAfmOnuJadyrEiscHc+zSvjtTV7+OuGfVRU1zEiuRM/v3Y0101IJalDYtAlShyLJPDXAkPNbCCwF5gD3NRwBzNLAxYDt7r79lM5ViQWlB2t4S/r9/Lqmj1szS+nfWIC147vw5xJ/ZjQr4vG0EuLcNLAd/daM7sPeJv6oZUL3H2Tmd0T3v4s8BjQHXg6/A+71t3Tj3fsGWqLyFmXlVfG71bt4s2sfVTWhBibmsS/Xz+Ga8f3oVM73c1Ly2LuLa+7PD093TMyMoIuQ6RR7s7fd5Tw7Ps7+XBHMee0bc3sCX24cVIaY1I1NbEEw8wy3T39RPvok7YiEaoLOW9vyueZ93aStbeMXp3a8sjMEdw0OU138xIVFPgiJ1FVWz9j5byV2eQUH2Fgj448/rWxXD8xlbatE4IuTyRiCnyR4yivrOGVNXt4Pjxj5djUJJ6+eSJXjU4mQTNWShRS4Is04O5k7S3jzQ37efXjPZSHZ6z8zQ0TmKIZKyXKKfAl7tXUhfg4p5Tlm/JZvrmA/WWVtDK4anQy37lsMOP6dgm6RJFmocCXuFRRXcvK7UUs31TAO1sLKTtaQ9vWrbhkWE8eunI400b0olvHNkGXKdKsFPgSNw4cqWbFlgKWbyrgg8+KqKoNkdQ+kctH9uKq0cl8ZWgPvR9WYpr+dUtMKz1Szdub8lmatZ9VO0uoCzl9ktpx46Q0rhzdm0kDutE6Qe+GlfigwJeYU3y46ouQX51dSl3I6d+9A3MvGcTMMcmMTU3Sw1eJSwp8iQlF5VW8tSmfZVn7WZ1dQshhYI+O3HPpIGaOSWF0n84KeYl7CnyJSu5OdvER/ralkP/ZUsDaXaWEHAb16Mi9lw1h1tgURqZ0UsiLNKDAl6hRXRti7a5S3tlSyN+2FrCrpAKA4b07cd/UIcwal8Lw3gp5keNR4EuLVny4ive2FfG3rQWs3F7M4apa2rRuxZTB3bnj4oFMHdFLLxMRiZACX1qMupCTU3yETfvK2LzvEB/vKmV97kHcoVentnx1fArTRvTmoiHdNXxSpAn0UyOBqK4Nsb2gnM37DrFxXxmb9h1iy/5DVFTXAdAmoRUj+3TmwcuHcfnIXnroKtIMFPhyVlTXhli1s5gVmwtYn3uQ7QXl1NTVv4uhY5sERvXpzDfT+zGqT2dG9+nM0F6daNNa4+NFmpMCX86Yypo63t9exNsb81mxpYDyylo6tklgYv+ufPvigYzpk8ToPp0Z0L0jrTT7pMgZp8CXZnW4qpZ3txby1sZ83t1WSEV1HUntE7lqdDIzxyRz0ZAetEvUHPIiQVDgy2krO1rDis0FvLVxPys/K6a6NkSPc9pw3bmpzByTzAWDupOo6QtEAqfAlyapqK7lf7YUsmT9PlZuL6K6LkSfpHbcPDmNmWNSOK9/V70kRKSFUeBLxKprQ7y/vYi/frqPFZsLOFpTR+/Obbn1wv5cMy6FCf26aCSNSAumwJcTqgs5q7NLWLJ+H8s27udQZS1dOyRy/cRUvjquD5MGdtOdvEiUUOAL1bUhig9XUVReRWH5539Xsu/gUf62tYjiw1V0bJPAVaOT+er4Plw8tIf65EWikAI/ToRCztb8clZnl7BxX1l9qB+qouhwFaVHqhs9plvHNkwa0I1rJ/Rh2oheGl0jEuUU+DEqFHK2F5azemcJH2WXsCanlIMVNQAkd25HclI70rp3IH1AV3p2akuvTu3o1alt/ded29LjnLa6ixeJMQr8GOHufFZ4mNXZJXy0sz7gP79z79etPdNH9ubCwd25YFB3+nRpH3C1IhIEBX4Uqws5a3eVsjRrP29tzKewvAqA1C7tmTq8Vzjgu2k2SREBIgx8M5sBPAkkAPPd/fFjto8AXgAmAj9x9ycabPs+cCfgQBbwLXevbJ7y409dyPk4Jxzym/IpKq+iXWIrpg7vxdQRvbhwUHf6dVPAi8iXnTTwzSwBeAqYDuQBa81sibtvbrBbKfAAcN0xx6aG149y96Nm9kdgDvC7Zqk+Tnwe8m9m7eOtjQUUH64P+WkjejFrbArTRvTSdMEiclKRpMQkYIe7ZwOY2UJgNvBF4Lt7IVBoZlcf53u0N7MaoAOw77SrjgPuTubuA7yxfu+XQv7qsX2YOqKnQl5ETkkkiZEK5DZYzgMmR3Jyd99rZk8Ae4CjwHJ3X97YvmY2F5gLkJaWFsnpY9L+sqMs/mQvizLzyCk+QrvEVlw+ojezxqYo5EXktESSHo19jNIjObmZdaX+fwMDgYPAn8zsFnd/+UsndJ8HzANIT0+P6PyxorKmjuWbC1iUmceHnxURcpg0sBv3XjaYWWNT6NhWIS8ipy+SJMkD+jVY7kvk3TJXADnuXgRgZouBKcCXAj/euDuf5pWxKDOXJev3caiyltQu7blv6hC+fl5f+nfvGHSJIhJjIgn8tcBQMxsI7KX+oetNEZ5/D3CBmXWgvkvnciCjKYXGgqraOrLyyliTU8ob6/byWeFh2rZuxcwxyfxTej8uHNRdLwIRkTPmpIHv7rVmdh/wNvXDMhe4+yYzuye8/VkzS6Y+yDsDITN7kPqROWvMbBHwCVALrCPcbRMPDlZUk7n7AGt3HSBzdymf5pVRXRsC4Ny0LvzH9WO5ZnwKndslBlypiMQDc2953eXp6emekRF9/xHILa1g7a5SMnYfIGNXKdsLDgOQmGCMSU0ivX9X0gd047z+XelxTtuAqxWRWGJmme6efqJ99DTwNNWFnBWb8/ntymzW7TkIQKd2rTmvf1dmT0jlvP5dGd+3C+3baOIxEQmWAr+JKmvqeP2TPOZ/kENO8RHSunXgp1eP5OKhPRjWq5P64kWkxVHgn6KDFdW89NFufrdqFyVHqhnfN4mnbprIjDHJehGIiLRoCvwI5ZZW8PyHOfxhbS5Ha+qYOrwncy8ZzAWDuum1fiISFRT4J7E1/xBPv7uTN7P208rg2vGpzL1kEMOTOwVdmojIKVHgn0BO8RGue+rvtG7VijsvHsi3LhpIclK7oMsSEWkSBf5xuDuPLN5AYkIrln//ElKS9NIQEYlueofdcfxhbS6rs0t5dNZIhb2IxAQFfiMKD1Xy70u3cMGgbsw5v9/JDxARiQIK/EY89pdNVNeG+OXXxmkEjojEDAX+Md7aWP/qwAevGMbAHpqxUkRihwK/gbKjNTz2l02MSunMnV8ZGHQ5IiLNSqN0Gnh82RaKD1fx/G3nk5ig34UiEluUamEf7SzhtY9zuesrgxjbNynockREmp0Cn/qJ0B5ZvIH+3Tvw4BXDgi5HROSMUJcO8OQ7n7GrpIJX75ysaYxFJGbF/R3+xr1lzFuZzTfT+zJlSI+gyxEROWPiOvBr60I8vHgDXTu04SezRgVdjojIGRXXXToL/p7Dxr2HePrmiSR10HtlRSS2xe0d/u6SI/x6xXamj+rNzDHJQZcjInLGxWXg18+EmUViq1b8YvYYTZ8gInEhLgP/rxv2s2pnCQ/PGqH57UUkbsRl4C/KzKNft/bceH5a0KWIiJw1cRf4ZRU1rNpRzKyxKbTSS8dFJI7EXeCv2FJAbciZOSYl6FJERM6quAv8ZVn76ZPUjvGaL0dE4kxEgW9mM8xsm5ntMLOHG9k+wsw+MrMqM/vBMdu6mNkiM9tqZlvM7MLmKv5UlVfW8MFnxcwcm6KROSISd076wSszSwCeAqYDecBaM1vi7psb7FYKPABc18gpngTecvdvmFkboMNpV91Ef9taSHVdiFljNe5eROJPJHf4k4Ad7p7t7tXAQmB2wx3cvdDd1wI1DdebWWfgEuD58H7V7n6wOQpviqVZ++nduS3n9usaVAkiIoGJJPBTgdwGy3nhdZEYBBQBL5jZOjObb2aNvjfQzOaaWYaZZRQVFUV4+sgdqarlvW1FzBidrNE5IhKXIgn8xtLRIzx/a2Ai8Iy7nwscAb70DADA3ee5e7q7p/fs2TPC00fu3W2FVNWGmDlWo3NEJD5FEvh5QL8Gy32BfRGePw/Ic/c14eVF1P8COOuWZeXT45w2nD+gWxDfXkQkcJEE/lpgqJkNDD90nQMsieTk7p4P5JrZ8PCqy4HNJzjkjDhaXce72wq5anQyCerOEZE4ddJROu5ea2b3AW8DCcACd99kZveEtz9rZslABtAZCJnZg8Aodz8E3A+8Ev5lkQ1868w05fje315ERXUds9SdIyJxLKL58N19KbD0mHXPNvg6n/qunsaOXQ+kN73E07ds4366dkhk8kB154hI/Ir5T9pW1dbxzpZCrhyVTOuEmG+uiMhxxXwCfvhZMYerapmpD1uJSJyL+cBfmpVP53atmTJYLygXkfgW04FfXRtixeZ8rhjVmzatY7qpIiInFdMpuGpnMYcqa5mlqZBFRGI78Jdl5XNO29ZcPFTdOSIiMRv4tXUhlm/O5/KRvWiXmBB0OSIigYvZwF+TU8qBihq92UpEJCxmA39p1n7aJyZw6bDmn4hNRCQaxWTg14WctzflM21EL9q3UXeOiAjEaOBn7Cql+HC1PmwlItJATAb+so35tG3diqnDewVdiohIixFzgR8KOcs27ufSYT3p2DaiueFEROJCzAX+utwDFByq0lTIIiLHiLnAX5qVT5uEVkwbqe4cEZGGYirw3Z23NubzlaE96NwuMehyRERalJgK/A15Zew9eFQvKhcRaURMBf7Sjftp3cqYPrJ30KWIiLQ4MRP47s6yrHymDOlBUgd154iIHCtmxi1W1oSYMrg7Fw7uHnQpIiItUswEfvs2CTz+9XFBlyEi0mLFTJeOiIicmAJfRCROKPBFROKEAl9EJE4o8EVE4oQCX0QkTijwRUTihAJfRCROmLsHXcOXmFkRsLuJh/cAipuxnKDFWnsg9toUa+2B2GtTrLUHvtym/u7e80QHtMjAPx1mluHu6UHX0VxirT0Qe22KtfZA7LUp1toDTWuTunREROKEAl9EJE7EYuDPC7qAZhZr7YHYa1OstQdir02x1h5oQptirg9fREQaF4t3+CIi0ggFvohInIiZwDezGWa2zcx2mNnDQdfTHMxsl5llmdl6M8sIup5TZWYLzKzQzDY2WNfNzFaY2Wfhv7sGWeOpOk6bfmZme8PXab2ZzQqyxlNhZv3M7F0z22Jmm8zse+H1UXudTtCmqLxOZtbOzD42s0/D7fl5eP0pX6OY6MM3swRgOzAdyAPWAje6++ZACztNZrYLSHf3qPzAiJldAhwGfu/uY8Lr/hModffHw7+Yu7r7j4Os81Qcp00/Aw67+xNB1tYUZpYCpLj7J2bWCcgErgNuJ0qv0wna9E2i8DqZmQEd3f2wmSUCHwLfA77GKV6jWLnDnwTscPdsd68GFgKzA64p7rn7SqD0mNWzgRfDX79I/Q9i1DhOm6KWu+9390/CX5cDW4BUovg6naBNUcnrHQ4vJob/OE24RrES+KlAboPlPKL4AjfgwHIzyzSzuUEX00x6u/t+qP/BBHoFXE9zuc/MNoS7fKKm+6MhMxsAnAusIUau0zFtgii9TmaWYGbrgUJghbs36RrFSuBbI+uiv68KLnL3icBM4Lvh7gRpeZ4BBgMTgP3ArwKtpgnM7BzgdeBBdz8UdD3NoZE2Re11cvc6d58A9AUmmdmYppwnVgI/D+jXYLkvsC+gWpqNu+8L/10I/Jn6rqtoVxDuY/28r7Uw4HpOm7sXhH8gQ8BzRNl1CvcLvw684u6Lw6uj+jo11qZov04A7n4QeA+YQROuUawE/lpgqJkNNLM2wBxgScA1nRYz6xh+4ISZdQSuBDae+KiosAS4Lfz1bcBfAqylWXz+Qxd2PVF0ncIPBJ8Htrj7rxtsitrrdLw2Ret1MrOeZtYl/HV74ApgK024RjExSgcgPMTqN0ACsMDd/z3Yik6PmQ2i/q4eoDXwarS1ycxeAy6jfhrXAuBfgTeAPwJpwB7gn9w9ah6CHqdNl1HfTeDALuDuz/tWWzozuxj4AMgCQuHVj1Lf5x2V1+kEbbqRKLxOZjaO+oeyCdTfpP/R3f/NzLpzitcoZgJfREROLFa6dERE5CQU+CIicUKBLyISJxT4IiJxQoEvIhInFPgiInFCgS8iEif+P81fS2+KVreBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating the model on accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_words(seed, no_words):\n",
    "    for i in range(no_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_seq_length-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=1)\n",
    "        new_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if predicted == index:\n",
    "                new_word = word\n",
    "                break\n",
    "        seed += \" \" + new_word\n",
    "    print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "ome will muttered be to the the the of the the of the of the the of the\n"
     ]
    }
   ],
   "source": [
    "# predicting or generating the poem with the seed text\n",
    "\n",
    "seed_text = 'ome will muttered'\n",
    "next_words = 15\n",
    "\n",
    "predict_words(seed_text, next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "southron called the haunted of the the of the and the of the the\n"
     ]
    }
   ],
   "source": [
    "# predicting or generating the poem with the seed text\n",
    "\n",
    "seed_text = 'southron called the haunted'\n",
    "next_words = 10\n",
    "\n",
    "predict_words(seed_text, next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "we should start back the of the the\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'we should start back'\n",
    "next_words = 4\n",
    "predict_words(seed_text, next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Hammers for builders the of the\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'Hammers for builders'\n",
    "next_words = 3\n",
    "predict_words(seed_text, next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "\n",
    "model.save('text_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model \n",
    "from keras.models import load_model\n",
    "model = load_model('text_generator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
